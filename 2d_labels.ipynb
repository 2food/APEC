{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from torch.utils.data import Dataset\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'IMG_2139': slice(0, 180, None),\n",
       "  'IMG_2140': slice(360, 540, None),\n",
       "  'IMG_2141': slice(720, 900, None),\n",
       "  'IMG_2142': slice(1080, 1260, None),\n",
       "  'IMG_2320': slice(1440, 1620, None),\n",
       "  'VID_20210123_091729': slice(1800, 1980, None),\n",
       "  'VID_20210123_104706': slice(2160, 2340, None),\n",
       "  'VID_20210123_110129': slice(2520, 2700, None),\n",
       "  'VID_20210123_111337': slice(2880, 3060, None),\n",
       "  'VID_20210123_111921': slice(3240, 3420, None)},\n",
       " {'IMG_2139': slice(180, 360, None),\n",
       "  'IMG_2140': slice(540, 720, None),\n",
       "  'IMG_2141': slice(900, 1080, None),\n",
       "  'IMG_2142': slice(1260, 1440, None),\n",
       "  'IMG_2320': slice(1620, 1800, None),\n",
       "  'VID_20210123_091729': slice(1980, 2160, None),\n",
       "  'VID_20210123_104706': slice(2340, 2520, None),\n",
       "  'VID_20210123_110129': slice(2700, 2880, None),\n",
       "  'VID_20210123_111337': slice(3060, 3240, None),\n",
       "  'VID_20210123_111921': slice(3420, 3600, None)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ClimbingDataset.test_seqs, data.ClimbingDataset.val_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, stop=None):\n",
    "    files = os.listdir(path)\n",
    "    files.sort(key=lambda s: int(s.split('.')[0]))\n",
    "    no_files = stop if stop else len(files)\n",
    "    files = files[:no_files]\n",
    "    data = np.zeros((no_files, 17, 3))\n",
    "    for i, f in tqdm(enumerate(files), total=no_files):\n",
    "        kp_frame = np.load(path + f, allow_pickle=True)\n",
    "        if len(kp_frame) > 0:\n",
    "            kp_frame = kp_frame[0]['keypoints']\n",
    "            data[i] = kp_frame\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c16021c34b48a0ba913ed00b15d749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3760.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder = '/media/tormod/Den Lille/Thesis/mmpose_results/'\n",
    "video = 'VID_20210123_111337'\n",
    "path = f'{folder}{video}/'\n",
    "\n",
    "data = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = [\"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\", \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\", \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\", \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\"]\n",
    "my_keypoints = {\"nose\": \"Nose\",\n",
    "                \"left_ear\": \"Left Ear\", \n",
    "                \"right_ear\": \"Right Ear\", \n",
    "                \"left_shoulder\": \"Left Shoulder\", \n",
    "                \"right_shoulder\": \"Right Shoulder\", \n",
    "                \"left_elbow\": \"Left Elbow\", \n",
    "                \"right_elbow\": \"Right Elbow\", \n",
    "                \"left_wrist\": \"Left Wrist\",\n",
    "                \"right_wrist\": \"Right Wrist\",\n",
    "                \"left_hip\": \"Left Hip\",\n",
    "                \"right_hip\": \"Right Hip\",\n",
    "                \"left_knee\": \"Left Knee\",\n",
    "                \"right_knee\": \"Right Knee\",\n",
    "                \"left_ankle\": \"Left Ankle\",\n",
    "                \"right_ankle\": \"Right Ankle\"}\n",
    "\n",
    "def keypoint_str(keypoint):\n",
    "    return f'{keypoint[0]:.2f},{keypoint[1]:.2f}'\n",
    "\n",
    "def outside(keypoint, img_shape):\n",
    "    return keypoint[0] < 0 or keypoint[1] < 0 or keypoint[0] >= img_shape[1] or keypoint[1] >= img_shape[0]\n",
    "\n",
    "def clear_tracks(tree):\n",
    "    tree = ET.parse(anno_file)\n",
    "    root = tree.getroot()\n",
    "    for t in root.findall('track'):\n",
    "        root.remove(t)\n",
    "    return tree\n",
    "\n",
    "def to_cvat(anno_file, out_file, data):\n",
    "    tree = ET.parse(anno_file)\n",
    "    tree = clear_tracks(tree)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('meta/task/original_size')\n",
    "    img_shape = int(size.find('height').text), int(size.find('width').text)\n",
    "    \n",
    "    write_conf = 0.8\n",
    "    \n",
    "    def add_track(track_id, label=None):\n",
    "        if label is None:\n",
    "            label = my_keypoints[keypoints[track_id]]\n",
    "        track = ET.SubElement(root, 'track')\n",
    "        track.set('id', str(track_id))\n",
    "        track.set('label', label)\n",
    "        track.set('source', 'mmpose')\n",
    "        return track\n",
    "    \n",
    "    def frame_loop(track, track_id, keypoint_fn, draw_if_fn, inferred=False):\n",
    "        guess_rate = 30 if inferred else 5\n",
    "        frange = range(data.shape[0])\n",
    "        frange = filter(lambda i: i%guess_rate == 0, frange)\n",
    "            \n",
    "        for frame_id in frange:\n",
    "            if draw_if_fn(frame_id) or frame_id==0:\n",
    "                point = ET.SubElement(track, 'points')\n",
    "                keypoint = keypoint_fn(frame_id)\n",
    "                point_str = keypoint_str(keypoint)\n",
    "                point.set('frame', str(frame_id))\n",
    "                point.set('outside', '1' if outside(keypoint, img_shape) else '0')\n",
    "                point.set('occluded', '0')\n",
    "                point.set('keyframe', '1')\n",
    "                point.set('points', point_str)\n",
    "    \n",
    "    \n",
    "    def draw_if_conf(joint_ids):\n",
    "        draw_if_fn = lambda frame_id: np.all(data[frame_id, joint_ids, 2] >= write_conf)\n",
    "        return draw_if_fn\n",
    "    \n",
    "    # Standard joints (in coco results)\n",
    "    for track_id in range(17):\n",
    "        if track_id in [1,2]:\n",
    "            continue\n",
    "        track = add_track(track_id)\n",
    "        standard_keypoint_fn = lambda frame_id: data[frame_id, track_id]\n",
    "        standard_draw_if_fn = draw_if_conf([track_id])\n",
    "        frame_loop(track, track_id, standard_keypoint_fn, standard_draw_if_fn)\n",
    "        \n",
    "    # Neck\n",
    "#     track_id = 18\n",
    "#     track = add_track(track_id, label='Neck')\n",
    "#     neck_keypoint_fn = lambda frame_id: data[frame_id, 5:7, 0:2].mean(axis=0)\n",
    "#     neck_draw_if_fn = draw_if_conf([5,6])\n",
    "#     frame_loop(track, track_id, neck_keypoint_fn, neck_draw_if_fn, inferred=True)\n",
    "        \n",
    "    # Left Hand\n",
    "    track_id = 19\n",
    "    track = add_track(track_id, label='Left Hand')\n",
    "    def lhand_keypoint_fn(frame_id):\n",
    "        elbow = data[frame_id, 7, 0:2]\n",
    "        wrist = data[frame_id, 9, 0:2]\n",
    "        keypoint = wrist + ((wrist - elbow) * 0.2)\n",
    "        return keypoint\n",
    "    lhand_draw_if_fn = draw_if_conf([7,9])\n",
    "    frame_loop(track, track_id, lhand_keypoint_fn, lhand_draw_if_fn, inferred=True)\n",
    "\n",
    "    # Rigth Hand\n",
    "    track_id = 20\n",
    "    track = add_track(track_id, label='Right Hand')\n",
    "    def rhand_keypoint_fn(frame_id):\n",
    "        elbow = data[frame_id, 8, 0:2]\n",
    "        wrist = data[frame_id, 10, 0:2]\n",
    "        keypoint = wrist + ((wrist - elbow) * 0.2)\n",
    "        return keypoint\n",
    "    rhand_draw_if_fn = draw_if_conf([8,10])\n",
    "    frame_loop(track, track_id, rhand_keypoint_fn, rhand_draw_if_fn, inferred=True)\n",
    "    \n",
    "        \n",
    "    # Left Foot\n",
    "    track_id = 21\n",
    "    track = add_track(track_id, label='Left Foot')\n",
    "    def lfoot_keypoint_fn(frame_id):\n",
    "        knee = data[frame_id, 13, 0:2]\n",
    "        ankle = data[frame_id, 15, 0:2]\n",
    "        keypoint = ankle + ((ankle - knee) * 0.2)\n",
    "        return keypoint\n",
    "    lfoot_draw_if_fn = draw_if_conf([13,15])\n",
    "    frame_loop(track, track_id, lfoot_keypoint_fn, lfoot_draw_if_fn, inferred=True)\n",
    "        \n",
    "    # Right Foot\n",
    "    track_id = 22\n",
    "    track = add_track(track_id, label='Right Foot')\n",
    "    def rfoot_keypoint_fn(frame_id):\n",
    "        knee = data[frame_id, 14, 0:2]\n",
    "        ankle = data[frame_id, 16, 0:2]\n",
    "        keypoint = ankle + ((ankle - knee) * 0.2)\n",
    "        return keypoint\n",
    "    rfoot_draw_if_fn = draw_if_conf([14,16])\n",
    "    frame_loop(track, track_id, rfoot_keypoint_fn, rfoot_draw_if_fn, inferred=True)\n",
    "\n",
    "    tree.write(out_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_folder = '/media/tormod/Den Lille/Thesis/annotations/'\n",
    "anno_file = f'{anno_folder}{video}.xml'\n",
    "out_file = '2d_out.xml'\n",
    "\n",
    "to_cvat(anno_file, out_file, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_xml(from_file, into_file, out_file, frame_limits=None):\n",
    "    into_tree = ET.parse(into_file)\n",
    "    into_root = into_tree.getroot()\n",
    "    \n",
    "    from_tree = ET.parse(from_file)\n",
    "    from_root = from_tree.getroot()\n",
    "    from_tracks = from_root.findall('track')\n",
    "    \n",
    "    out_tree = ET.parse(into_file)\n",
    "    out_tree = clear_tracks(out_tree)\n",
    "    out_root = out_tree.getroot()\n",
    "    \n",
    "    #print(into_root.findall('track'))\n",
    "    for into_track in into_root.findall('track'):\n",
    "        attrib = into_track.attrib\n",
    "        label = attrib['label']\n",
    "        from_track = from_root.find(f\"track[@label='{label}']\")\n",
    "        \n",
    "        limit = 4250 \n",
    "        if frame_limits is not None and label in frame_limits:\n",
    "            limit = frame_limits[label]\n",
    "            print(label, limit)\n",
    "        \n",
    "        out_track = ET.SubElement(out_root, 'track')\n",
    "        out_track.set('label', label)\n",
    "        out_track.set('source', 'merge')\n",
    "        \n",
    "        \n",
    "        for point in into_track.getchildren():\n",
    "            if int(point.attrib['frame']) <= limit:\n",
    "                out_track.append(point)\n",
    "\n",
    "        for point in from_track.getchildren():\n",
    "            if int(point.attrib['frame']) > limit:\n",
    "                out_track.append(point)\n",
    "    \n",
    "    out_tree.write(out_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merge_xml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-72aba1924889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 'Left Ear': 4560}\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmerge_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minto_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_limits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'merge_xml' is not defined"
     ]
    }
   ],
   "source": [
    "into_file = '/home/tormod/Downloads/IMG_2139.xml'\n",
    "from_file = '2d_out.xml'\n",
    "out_file = 'temp.xml'\n",
    "\n",
    "frame_limits = {'Nose': 6830,\n",
    "                'Left Ear': 4560}\n",
    "\n",
    "merge_xml(from_file, into_file, out_file, frame_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
