{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/lite/guide/python\n",
    "# https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python\n",
    "# https://www.tensorflow.org/lite/models/pose_estimation/overview\n",
    "# posenet paper: https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Kendall_PoseNet_A_Convolutional_ICCV_2015_paper.pdf\n",
    "import tflite_runtime.interpreter as tflite\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.util import img_as_float32, img_as_ubyte, img_as_uint\n",
    "from skimage.transform import resize\n",
    "import urllib.request\n",
    "import json \n",
    "\n",
    "# pip install tfjs-graph-converter\n",
    "import tfjs_graph_converter.api as tfjs\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from os.path import isfile, join\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_uri = 'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/'\n",
    "mobilenet_uris = [\"mobilenet/float/050/group1-shard1of1.bin\",\n",
    "                  \"mobilenet/float/050/model-stride16.json\",\n",
    "                  \"mobilenet/float/050/model-stride8.json\",\n",
    "                  \"mobilenet/float/075/group1-shard1of2.bin\",\n",
    "                  \"mobilenet/float/075/group1-shard2of2.bin\",\n",
    "                  \"mobilenet/float/075/model-stride16.json\",\n",
    "                  \"mobilenet/float/075/model-stride8.json\",\n",
    "                  \"mobilenet/float/100/group1-shard1of4.bin\",\n",
    "                  \"mobilenet/float/100/group1-shard2of4.bin\",\n",
    "                  \"mobilenet/float/100/group1-shard3of4.bin\",\n",
    "                  \"mobilenet/float/100/model-stride16.json\",\n",
    "                  \"mobilenet/float/100/model-stride8.json\"]\n",
    "resnet_uris = ['resnet50/float/group1-shard11of23.bin',\n",
    "               'resnet50/float/group1-shard10of23.bin',\n",
    "               'resnet50/float/group1-shard12of23.bin',\n",
    "               'resnet50/float/group1-shard13of23.bin',\n",
    "               'resnet50/float/group1-shard14of23.bin',\n",
    "               'resnet50/float/group1-shard15of23.bin',\n",
    "               'resnet50/float/group1-shard16of23.bin',\n",
    "               'resnet50/float/group1-shard17of23.bin',\n",
    "               'resnet50/float/group1-shard18of23.bin',\n",
    "               'resnet50/float/group1-shard19of23.bin',\n",
    "               'resnet50/float/group1-shard1of23.bin',\n",
    "               'resnet50/float/group1-shard20of23.bin',\n",
    "               'resnet50/float/group1-shard21of23.bin',\n",
    "               'resnet50/float/group1-shard22of23.bin',\n",
    "               'resnet50/float/group1-shard23of23.bin',\n",
    "               'resnet50/float/group1-shard2of23.bin',\n",
    "               'resnet50/float/group1-shard3of23.bin',\n",
    "               'resnet50/float/group1-shard4of23.bin',\n",
    "               'resnet50/float/group1-shard5of23.bin',\n",
    "               'resnet50/float/group1-shard6of23.bin',\n",
    "               'resnet50/float/group1-shard7of23.bin',\n",
    "               'resnet50/float/group1-shard8of23.bin',\n",
    "               'resnet50/float/group1-shard9of23.bin',\n",
    "               'resnet50/float/model-stride16.json',\n",
    "               'resnet50/float/model-stride32.json',\n",
    "               'resnet50/quant1/group1-shard1of6.bin',\n",
    "               'resnet50/quant1/group1-shard2of6.bin',\n",
    "               'resnet50/quant1/group1-shard3of6.bin',\n",
    "               'resnet50/quant1/group1-shard4of6.bin',\n",
    "               'resnet50/quant1/group1-shard5of6.bin',\n",
    "               'resnet50/quant1/group1-shard6of6.bin',\n",
    "               'resnet50/quant1/model-stride16.json',\n",
    "               'resnet50/quant1/model-stride32.json',\n",
    "               'resnet50/quant2/group1-shard10of12.bin',\n",
    "               'resnet50/quant2/group1-shard11of12.bin',\n",
    "               'resnet50/quant2/group1-shard12of12.bin',\n",
    "               'resnet50/quant2/group1-shard1of12.bin',\n",
    "               'resnet50/quant2/group1-shard2of12.bin',\n",
    "               'resnet50/quant2/group1-shard3of12.bin',\n",
    "               'resnet50/quant2/group1-shard4of12.bin',\n",
    "               'resnet50/quant2/group1-shard5of12.bin',\n",
    "               'resnet50/quant2/group1-shard6of12.bin',\n",
    "               'resnet50/quant2/group1-shard7of12.bin',\n",
    "               'resnet50/quant2/group1-shard8of12.bin',\n",
    "               'resnet50/quant2/group1-shard9of12.bin',\n",
    "               'resnet50/quant2/model-stride16.json',\n",
    "               'resnet50/quant2/model-stride32.json']\n",
    "\n",
    "# resnet\n",
    "# stride can be 16 or 32\n",
    "\n",
    "# mobilenet\n",
    "# stride can be 8, 16 or 32\n",
    "# multiplier can be \"100\", \"075\", or \"050\"\n",
    "\n",
    "def get_model(architecture='resnet'):\n",
    "    file_uris = ''\n",
    "    if architecture== 'resnet':\n",
    "        file_uris = resnet_uris\n",
    "    else:\n",
    "        file_uris = mobilenet_uris\n",
    "    for file_uri in file_uris:\n",
    "        uri = base_uri + file_uri\n",
    "        save_path = 'json-models/' + \"/\".join(file_uri.split(\"/\")[:-1])\n",
    "        Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "        urlretrieve(uri, 'json-models/' + file_uri)\n",
    "        #print(save_path)\n",
    "\n",
    "get_model('mobilenet')\n",
    "get_model('resnet')\n",
    "\n",
    "#!rm -rf saved_model\n",
    "#tfjs.graph_model_to_saved_model('json-model', 'saved_model')\n",
    "\n",
    "\n",
    "# https://github.com/octiapp/KerasPersonLab/blob/master/demo.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved_model/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'saved_model/saved_model.pb'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf saved_model\n",
    "tfjs.graph_model_to_saved_model('json-model', 'saved_model', compat_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('saved_model')\n",
    "tflite_model = converter.convert()\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Encountered unresolved custom op: PosenetDecoderOp.Node number 89 (PosenetDecoderOp) failed to prepare.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4b165b7d70c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpose_est_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_img_pose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-4b165b7d70c5>\u001b[0m in \u001b[0;36mpose_est_mult\u001b[0;34m(imgs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpose_est_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtflite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tflite_runtime/interpreter.py\u001b[0m in \u001b[0;36mallocate_tensors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mallocate_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAllocateTensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_safe_to_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Encountered unresolved custom op: PosenetDecoderOp.Node number 89 (PosenetDecoderOp) failed to prepare.\n"
     ]
    }
   ],
   "source": [
    "#model_file = 'posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite'\n",
    "model_file = 'posenet_resnet_50_928_672_16_quant_cpu_decoder.tflite'\n",
    "#model_file = 'posenet_resnet_50_928_672_16_quant_edgetpu_decoder.tflite'\n",
    "#model_file = 'model.tflite'\n",
    "img_file = 'elon-musk.jpg'\n",
    "\n",
    "no_kps = 17\n",
    "\n",
    "def pose_est(interpreter, img):\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    #print(input_details)\n",
    "\n",
    "    input_shape = input_details[0]['shape']\n",
    "    input_data = img \n",
    "    input_data = input_data[np.newaxis]\n",
    "    input_data = img_as_ubyte(resize(input_data, input_shape))\n",
    "    print(input_data.dtype)\n",
    "    \n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    heatmap = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    offset = interpreter.get_tensor(output_details[1]['index'])[0]\n",
    "    \n",
    "    # Infer keypoint coordinates from heatmap and offset\n",
    "    coords = np.empty((no_kps,2))\n",
    "    for i in range(no_kps):\n",
    "        y = heatmap[:,:,i].max(axis=1).argmax()\n",
    "        x = heatmap[:,:,i].max(axis=0).argmax()\n",
    "        coords[i,0] = (y / (heatmap.shape[0]-1)) * input_data[0].shape[0] + offset[y, x, i]\n",
    "        coords[i,1] = (x / (heatmap.shape[1]-1)) * input_data[0].shape[1] + offset[y, x, i+no_kps]\n",
    "    coords[:,0] = (coords[:,0] / input_data[0].shape[0]) * img.shape[0]\n",
    "    coords[:,1] = (coords[:,1] / input_data[0].shape[1]) * img.shape[1]\n",
    "    return coords\n",
    "\n",
    "\n",
    "def pose_est_mult(imgs):\n",
    "    interpreter = tflite.Interpreter(model_path=model_file)\n",
    "    interpreter.allocate_tensors()\n",
    "    coords = []\n",
    "    for i in imgs:\n",
    "        coords.append(pose_est(interpreter, i))\n",
    "    \n",
    "    return np.concatenate(coords)\n",
    "\n",
    "\n",
    "def plot_img_pose(img, coords, include_oob=False):\n",
    "    if not include_oob:\n",
    "        coords[:,0] = coords[:,0].clip(min=0, max=img.shape[0])\n",
    "        coords[:,1] = coords[:,1].clip(min=0, max=img.shape[1])\n",
    "    \n",
    "    fig = plt.figure(figsize=(img.shape[0]/100, img.shape[1]/100))\n",
    "    plt.imshow(img)\n",
    "    plt.scatter(coords[:,1], coords[:,0])\n",
    "    plt.axis('off')\n",
    "    fig.tight_layout(pad=0)\n",
    "    plt.margins(0)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    image_from_plot = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    walls = (image_from_plot == 255).all(axis=2).all(axis=0)\n",
    "    image_from_plot = image_from_plot[:, np.logical_not(walls),:]\n",
    "    plt.close()\n",
    "    return image_from_plot\n",
    "\n",
    "imgs = [plt.imread(img_file)]\n",
    "coords = pose_est_mult(imgs)\n",
    "\n",
    "img = plot_img_pose(imgs[0], coords)\n",
    "plt.imshow(imgs[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video2Frames(filename, outpath, fps=2.0):\n",
    "    vidcap = cv2.VideoCapture(filename)\n",
    "    sec = 0\n",
    "    count=1\n",
    "    \n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if not os.path.isdir(outpath):\n",
    "        os.mkdir(outpath)\n",
    "    files = glob.glob(outpath+'*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    while hasFrames:# and sec <= 30:\n",
    "        cv2.imwrite(f'{outpath}{count}.jpg', image)  \n",
    "        \n",
    "        count += 1\n",
    "        sec = sec + (1/fps)\n",
    "        sec = round(sec, 2)\n",
    "        \n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "        hasFrames,image = vidcap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video2Frames('videos/IMG_2139.MOV', 'frames/IMG_2139/', fps=20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_num(name):\n",
    "    name = name.split('/')[-1]\n",
    "    name = name.split('.')[0]\n",
    "    return int(name)\n",
    "\n",
    "def pose_est_frames(framepath, outname, fps=2.0):\n",
    "    framenames = [framepath+f for f in os.listdir(framepath) if isfile(join(framepath, f))]\n",
    "    framenames.sort(key=get_frame_num)\n",
    "    \n",
    "    frame = cv2.imread(framenames[0]) \n",
    "    height, width, layers = frame.shape\n",
    "    downsize = 0.5\n",
    "    size = (int(width*downsize), int(height*downsize))\n",
    "    \n",
    "    if os.path.isfile(outname):\n",
    "        os.remove(outname)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(outname, fourcc, fps, size)\n",
    "    for framename in tqdm(framenames[:1000]):\n",
    "        frame = cv2.imread(framename)\n",
    "        # writing to a image array\n",
    "        img = img_as_float32(frame)\n",
    "        coords = pose_est_mult([img])\n",
    "        \n",
    "        img = plot_img_pose(img, coords, include_oob=False)\n",
    "        img = cv2.resize(img, size)\n",
    "        out.write(img)\n",
    "        #cv2.imshow('frame',img)\n",
    "        #if cv2.waitKey(1) and 0xFF == ord('q'):\n",
    "        #    break\n",
    "        del img, frame\n",
    "    \n",
    "    # Release everything if job is finished\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    del out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4a2b0e9a7e4085ae976f67ea4eff29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pose_est_frames('frames/IMG_2139/', 'posevideos/IMG_2139.mp4', fps=20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
