{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "spare-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torchvision\n",
    "from torchvision.datasets.video_utils import VideoClips\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "incredible-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedirs_ifno(paths):\n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            files = glob.glob(f'{path}*')\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "        else:\n",
    "            os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "useful-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "cliplength = 30\n",
    "input_folder = 'videos/'\n",
    "video_names = ['IMG_2139.MOV', \n",
    "               'IMG_2140.MOV',\n",
    "               'IMG_2141.MOV',\n",
    "               'IMG_2142.MOV',\n",
    "               'VID_20210123_091729.mp4',\n",
    "               'VID_20210123_104706.mp4',\n",
    "               'VID_20210123_110129.mp4',\n",
    "               'VID_20210123_111337.mp4',\n",
    "               'VID_20210123_111921.mp4']\n",
    "\n",
    "video_paths = list(map(lambda s: input_folder+s, video_names))\n",
    "output_folder = '/home/tormod/ucph-erda-home/frames/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aerial-suggestion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ffef5ac4054f6ebb716979ecd42b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'video_paths': ['videos/IMG_2139.MOV',\n",
       "  'videos/IMG_2140.MOV',\n",
       "  'videos/IMG_2141.MOV',\n",
       "  'videos/IMG_2142.MOV',\n",
       "  'videos/VID_20210123_091729.mp4',\n",
       "  'videos/VID_20210123_104706.mp4',\n",
       "  'videos/VID_20210123_110129.mp4',\n",
       "  'videos/VID_20210123_111337.mp4',\n",
       "  'videos/VID_20210123_111921.mp4'],\n",
       " 'video_pts': [tensor([     0,     20,     40,  ..., 136619, 136639, 136659]),\n",
       "  tensor([     0,     20,     40,  ..., 152230, 152250, 152270]),\n",
       "  tensor([    0,    20,    40,  ..., 69610, 69630, 69650]),\n",
       "  tensor([    0,    20,    40,  ..., 52118, 52138, 52158]),\n",
       "  tensor([       0,    11024,    14020,  ..., 34079538, 34082538, 34085529]),\n",
       "  tensor([       0,    14763,    17755,  ..., 46547926, 46550933, 46553925]),\n",
       "  tensor([       0,     2992,     5979,  ..., 13878862, 13881851, 13884841]),\n",
       "  tensor([       0,    26798,    29797,  ..., 11418545, 11421555, 11424554]),\n",
       "  tensor([       0,    12662,    15661,  ..., 14127910, 14130909, 14133908])],\n",
       " 'video_fps': [29.978270253660035,\n",
       "  29.978330816205922,\n",
       "  29.978469929668435,\n",
       "  29.97815171144927,\n",
       "  29.995142059555533,\n",
       "  29.992321012149496,\n",
       "  30.11481041955303,\n",
       "  29.612638856280082,\n",
       "  28.890336478835152]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vclips = VideoClips(video_paths, \n",
    "                    clip_length_in_frames=cliplength,\n",
    "                    frames_between_clips=cliplength,\n",
    "                    num_workers=8)\n",
    "vclips.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "brief-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip(vclips, video_idx, idx):\n",
    "    start = sum([vclips.clips[v_idx].shape[0] for v_idx in range(video_idx)])\n",
    "    return vclips.get_clip(start+idx)\n",
    "\n",
    "\n",
    "def save_frames(vclips: VideoClips):\n",
    "    for v_idx in range(vclips.num_videos()):\n",
    "        vname = video_names[v_idx].split('.')[0]\n",
    "        print(f'Processing {vname}...')\n",
    "        vout = f'{output_folder}{vname}/'\n",
    "        makedirs_ifno([vout])\n",
    "        \n",
    "        no_clips_this_vid = vclips.clips[v_idx].shape[0]\n",
    "        for i in trange(no_clips_this_vid):\n",
    "            clip = get_clip(vclips, v_idx, i)\n",
    "            frames = clip[0]\n",
    "            for j, f in enumerate(frames):\n",
    "                f = f.permute(2,0,1)\n",
    "                torchvision.io.write_png(f, f'{vout}{i*cliplength+j}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cardiovascular-davis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing IMG_2139...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41579e5f62944936b680200d8e36e71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tormod/anaconda3/envs/apec/lib/python3.7/site-packages/torchvision/io/video.py:159: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing IMG_2140...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd452b9e2324b3a884d52eb3519e0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing IMG_2141...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f8759cd4034e959bab525a0b4305fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing IMG_2142...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ba6ac3979d4d21811d0792ecdbebe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing VID_20210123_091729...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74b995bf0c747fab15fe69d2c6ebe5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/378 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-531419830b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvclips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-945aa347b9b3>\u001b[0m in \u001b[0;36msave_frames\u001b[0;34m(vclips)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{vout}{i*cliplength+j}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/apec/lib/python3.7/site-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mwrite_png\u001b[0;34m(input, filename, compression_level)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \"\"\"\n\u001b[1;32m    148\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mwrite_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apec/lib/python3.7/site-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mwrite_file\u001b[0;34m(filename, data)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mwritten\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_frames(vclips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-religion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
