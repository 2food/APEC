{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torchvision\n",
    "from tqdm.auto import tqdm, trange\n",
    "import mmcv\n",
    "from mmcv import VideoReader\n",
    "from typing import List\n",
    "from utils import makedirs_ifno, imshownp\n",
    "import data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate features from hmr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef8f405aad649f988f64c8b1746f823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_folder = '/home/tormod/ucph-erda-home/hmr_results'\n",
    "feat_folder = '/home/tormod/ucph-erda-home/hmr_features'\n",
    "for name in tqdm(data.stripped_names):\n",
    "    feat_res = np.load(f'{res_folder}/{name}.npy', allow_pickle=True)\n",
    "    features = [r['features'] for r in feat_res]\n",
    "    features = np.stack(features)\n",
    "    np.save(f'{feat_folder}/{name}.npy', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/media/tormod/Den\\ Lille/Thesis/videos/'\n",
    "video_names = data.video_names\n",
    "stripped_names = [v.split('.')[0] for v in video_names] # without .type\n",
    "video_paths = [input_folder+v for v in video_names]\n",
    "output_folder = '/media/tormod/Den Lille/Thesis/frames/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = [VideoReader(f, cache_capacity=1) for f in video_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in [0,2000,5000]:\n",
    "    imshownp(vids[0][frame], bgr=True, savename=f'first_vid_{frame}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames(vids: List[VideoReader]):\n",
    "    for i, v in enumerate(vids):\n",
    "        vname = stripped_names[i]\n",
    "        print(f'Processing {vname}...')\n",
    "        video_folder = f'{output_folder}{vname}/'\n",
    "        makedirs_ifno([video_folder])\n",
    "        for j, f in enumerate(tqdm(v)):\n",
    "            mmcv.imwrite(f, f'{video_folder}{j:06d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing IMG_2320...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9399df52196e4a70804a105c9ec74bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7580.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_frames(vids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join MMPose predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mmpose_data(path, stop=None):\n",
    "    files = os.listdir(path)\n",
    "    files.sort(key=lambda s: int(s.split('.')[0]))\n",
    "    no_files = stop if stop else len(files)\n",
    "    files = files[:no_files]\n",
    "    data = np.zeros((no_files, 17, 3))\n",
    "    for i, f in tqdm(enumerate(files), total=no_files):\n",
    "        kp_frame = np.load(path + f, allow_pickle=True)\n",
    "        if len(kp_frame) > 0:\n",
    "            kp_frame = kp_frame[0]['keypoints']\n",
    "            data[i] = kp_frame\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_folder = '/home/tormod/ucph-erda-home/mmpose_results'\n",
    "out_folder = '/home/tormod/ucph-erda-home/mmpose_anno'\n",
    "makedirs_ifno([out_folder+'/'])\n",
    "for name in data.stripped_names:\n",
    "    mmpose_data = load_mmpose_data(f'{in_folder}/{name}/')\n",
    "    np.save(f'{out_folder}/{name}.npy', mmpose_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load('/home/tormod/ucph-erda-home/IMG_2139.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process H36M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving pose data for subject 1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/tormod/ucph-erda-home/DIKU_Image_Human36M/DatasetSubjects/annotations/Human36M_subject1_camera.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2b65abe8cfd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubjects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprocess_h36m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pose_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/APEC/scripts/process_h36m.py\u001b[0m in \u001b[0;36msave_pose_data\u001b[0;34m(subject_id)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mjoint_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{h36m_folder}/annotations/Human36M_subject{subject_id}_joint_3d.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mcam_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcam_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/tormod/ucph-erda-home/DIKU_Image_Human36M/DatasetSubjects/annotations/Human36M_subject1_camera.json'"
     ]
    }
   ],
   "source": [
    "from scripts import process_h36m\n",
    "process_h36m.h36m_folder = '/home/tormod/ucph-erda-home/DIKU_Image_Human36M/DatasetSubjects'\n",
    "process_h36m.h36m_out_folder = '/media/tormod/Den Lille/Thesis/h36m'\n",
    "subjects = [1,5,6,7,8,9,11]\n",
    "for sub in subjects:\n",
    "    process_h36m.save_pose_data(sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
